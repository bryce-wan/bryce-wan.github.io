<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Chenyang (Bryce) Wan</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon.ico">

  <!-- Google Analytics
  
  <script>
      (function(i, s, o, g, r, a, m) {
          i['GoogleAnalyticsObject'] = r;
          i[r] = i[r] || function() {
              (i[r].q = i[r].q || []).push(arguments)
          }, i[r].l = 1 * new Date();
          a = s.createElement(o),
              m = s.getElementsByTagName(o)[0];
          a.async = 1;
          a.src = g;
          m.parentNode.insertBefore(a, m)
      })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'G-S3BTCD8VTF', 'auto');
      ga('send', 'pageview');

  </script>
   -->


<!-- Google tag (gtag.js) -->
  

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-S3BTCD8VTF"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-S3BTCD8VTF');
  </script>
  

</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">Chenyang (Bryce) Wan</h2>
        </a>
        <ul>
          <li><a href="/">About</a></li>
          <li><a href="/portfolio/">Portfolio</a></li>
        </ul>
    </div>
  </nav>

    <main>
      <div class="post">
  <h2 class="post-title">3D Reconstruction and Visual Localization in the Campus</h2>
  <div class="post-line"></div>

  <h2 id="introduction">Introduction</h2>

<p>Term project (independent work) for the course Introduction to Computer Vision (2023 Spring &amp; Summer), Zhejiang University</p>

<h2 id="supervisor">Supervisor</h2>

<p>Prof. <a href="https://www.xzhou.me"><strong>Xiaowei Zhou</strong></a></p>

<h2 id="project-description">Project Description</h2>

<p>In this project, the aim is to reconstruct a building in our campus using SfM and then complete the visual localization task based on query images (to get a 6 DOF camera pose with the 3D model reconstructed and the query image). I first took a large number of photos of a building on campus during the day and used these photos to reconstruct a 3D sparse model of the building using <a href="https://github.com/cvg/Hierarchical-Localization"><strong>hloc</strong></a> (a hierarchical localization toolbox). During the reconstruction process, I used several different algorithms for the reconstruction and compared the results. Next, I took many photos of the building at night with low brightness and used these photos for visual localization. I did this first using the localization algorithms already implemented in hloc, and then I trained our own neural network based on <a href="https://github.com/cvg/pixloc"><strong>pixloc</strong></a> for end-to-end visual localization testing. Ultimately, we compared these two visual localization schemes (mainly measured by the mean reprojection error).</p>

<h2 id="techique">Techique</h2>

<p>I complete the whole job mainly with python. I used <strong>hloc</strong> to reconstruct the 3D model of the building, and implemented the visual localization function with <strong>pixloc</strong> by training our own model.</p>

<h2 id="duration">Duration</h2>

<p>It takes about one month to complete the project (in Dec 2023).</p>

<h2 id="result">Result</h2>

<ul>
  <li>Here are the visualization results of the keypoints in the database images.</li>
</ul>

<center>

<table><tr>
<td><img src="/assets/demo/3D_reconstruction/kps1.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/kps2.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/kps3.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/kps4.png" width="800" border="1" /></td>
</tr></table>

blue: visible in the 3D model &nbsp; &nbsp; red: invisible in the 3D model
</center>

<p><br /></p>

<center>

<table><tr>
<td><img src="/assets/demo/3D_reconstruction/depth1.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/depth2.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/depth3.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/depth4.png" width="800" border="1" /></td>
</tr></table>

estimated depth of the keypoints

</center>

<ul>
  <li>Here are the reconstructed 3D model and the estimated camera poses.</li>
</ul>

<!-- 3d model -->
<center>

<table><tr>
<td><img src="/assets/demo/3D_reconstruction/reconstruction_1.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/reconstruction_2.png" width="800" border="1" /></td>
</tr></table>

<table><tr>
<td><img src="/assets/demo/3D_reconstruction/reconstruction_3.png" width="800" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/reconstruction_4.png" width="800" border="1" /></td>
</tr></table>

sparse 3D reconstruction model
</center>

<p><br /></p>

<!-- camera poses -->
<center>

<img src="/assets/demo/3D_reconstruction/reconstruction_camera.png" width="800" alt="3D reconstruction model and estimated camera poses" border="1" />

visualization of the camera poses
</center>

<ul>
  <li>The visual localization results of the pixloc are shown below. For each query image, we first find the closest image in the database (which has a known camera pose) and obtain the relative pose relation. At this point we also get the absolute camera pose of the query image. The animation exhibits the relative pose of the query image with respect to the reference image.</li>
</ul>

<center>

<table><tr>
<td><img src="/assets/demo/3D_reconstruction/pixloc_1.png" width="450" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/pixloc_2.png" width="450" border="1" /></td>
</tr></table>

green: keypoints in the reference image &nbsp; &nbsp; red: keypoints in the query image &nbsp;

</center>

<p><br /></p>

<center>

<video controls="controls" width="400">
    <source src="/assets/demo/3D_reconstruction/pixloc_1.mp4" type="video/mp4" />
</video>

<video controls="controls" width="400">
    <source src="/assets/demo/3D_reconstruction/pixloc_2.mp4" type="video/mp4" />
</video>
<br />

Mapping and transformation of the keypoints
</center>

<p><br /></p>

<center>

<img src="/assets/demo/3D_reconstruction/pixloc_vis_1.png" width="800" border="1" />
<img src="/assets/demo/3D_reconstruction/pixloc_vis_2.png" width="800" border="1" />

visualization of the camera poses

</center>

<ul>
  <li>The charts below show the mean reprojection error and the time to localize a query image on the basis of 3D models reconstructed using different algorithms (the independent variable is the tolerance for error).</li>
</ul>

<center>

<table><tr>
<td><img src="/assets/demo/3D_reconstruction/mre_compare.png" border="1" /></td>
<td><img src="/assets/demo/3D_reconstruction/loc_time_compare.png" border="1" /></td>
</tr></table>
left: mean reprojection error &nbsp; &nbsp; right: time cost
</center>

<ul>
  <li>The confidence of the visual localization result is presented in the form of a heat map.</li>
</ul>

<center>

<video controls="controls" width="600">
    <source src="/assets/demo/3D_reconstruction/confidence.mp4" type="video/mp4" />
</video>

</center>


</div>

<div class="pagination">
  
  
    <a href="/2023-12-18/7-DOF-space-robot" class="right next">Next</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2024-02-23 11:01:05 +0800">2024</time> Chenyang Wan. <a href="https://github.com/kssim/about-portfolio/">A.P</a> theme.
      </span>
    </footer>
  </body>
</html>
